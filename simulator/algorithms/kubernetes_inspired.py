# Importing EdgeSimPy components
from edge_sim_py import *

# Importing native Python modules/packages

import time

# Importing helper functions
from simulator.helper_functions import *

# Importing EdgeSimPy extensions
from simulator.extensions import *

"""
KUBERNETES STANDARD ALGORITHM FOR EDGE COMPUTING
Implements authentic Kubernetes behavior:
- Resource-based scheduling (CPU, RAM) - NO latency consideration
- QoS based on requests/limits (simulated via resource ratios)
- NO proactive migration
- NO automatic rebalancing
- Reactive pod recreation on node failures only
"""

"""
KUBERNETES STANDARD ALGORITHM FOR EDGE COMPUTING (Enhanced Version)
====================================================================

Implements authentic Kubernetes behavior with OPTIONAL enhancements:

BASELINE (Kubernetes Standard):
  - Resource-based scheduling (CPU, RAM) - NO latency consideration
  - QoS based on requests/limits
  - NO proactive migration
  - Reactive pod recreation on node failures only
  - Registry-only layer downloads

ENHANCEMENTS (Optional - configurable):
  - P2P Layer Download (edge servers share layers)
  - Live Migration (service stays available during pod recreation)

Usage:
  kubernetes_inspired(parameters={
      "current_step": 1,
      "enable_p2p": True,          # Enable P2P layer sharing
      "enable_live_migration": True # Enable live migration during failures
  })
"""

def k8s_check_and_deprovision_inactive_services(current_step):
    """
    Vers√£o local K8S para limpar servi√ßos (Pod Termination).
    """
    services_to_remove = []
    for user in User.all():
        for app in user.applications:
            # Se o usu√°rio parou de acessar
            if not is_user_accessing_application(user, app, current_step):
                for service in app.services:
                    # ‚úÖ N√ÉO remover se migra√ß√£o em andamento
                    if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                        last_migration = service._Service__migrations[-1]
                        if last_migration.get("end") is None:
                            continue

                    if service.server:
                        services_to_remove.append(service)
    
    for service in services_to_remove:
        # Libera recursos
        # Verifica se service.server ainda existe para evitar AttributeError em cascata
        if service.server:
            service.server.cpu_demand -= service.cpu_demand
            service.server.memory_demand -= service.memory_demand
            
            # ‚úÖ CORRE√á√ÉO: Verificar se disk_demand existe no servi√ßo antes de subtrair
            if hasattr(service, 'disk_demand'):
                service.server.disk_demand -= service.disk_demand
            elif hasattr(service, 'disk'):
                 # Fallback raro se atributo chamar apenas 'disk'
                 service.server.disk_demand -= service.disk

            if service in service.server.services:
                service.server.services.remove(service)
            
            service.server = None
            service._available = False

# ============================================================================
# GLOBAL CONFIGURATION
# ============================================================================

_K8S_CONFIG = {
    "enable_p2p": False,
    "enable_live_migration": False,
    "enable_proactive_sla_migration": False,
    "enable_failure_prediction": False,
}

_k8s_prediction_quality = {
        "proactive_migrations": [],
        "true_positives": 0,
        "false_positives": 0,
        "false_negatives": 0,
}

_k8s_total_execution_time = 0.0

def configure_kubernetes_enhancements(
    enable_p2p=False, 
    enable_live_migration=False,
    enable_proactive_sla_migration=False,
    enable_failure_prediction=False
):
    """
    Configura recursos OPCIONAIS para Kubernetes.
    
    Args:
        enable_p2p: Se True, habilita download P2P de camadas
        enable_live_migration: Se True, mant√©m pod dispon√≠vel durante migra√ß√£o
        enable_proactive_sla_migration: Se True, migra ANTES da falha quando SLA √© violado
    
    Examples:
        # Kubernetes PADR√ÉO (baseline)
        configure_kubernetes_enhancements(
            enable_p2p=False, 
            enable_live_migration=False,
            enable_proactive_sla_migration=False
        )
        
        # Kubernetes + Proactive SLA + Live Migration (TESTE REAL de Live Migration!)
        configure_kubernetes_enhancements(
            enable_p2p=True, 
            enable_live_migration=True,
            enable_proactive_sla_migration=True
        )
    """

    global _K8S_CONFIG
    _K8S_CONFIG["enable_p2p"] = enable_p2p
    _K8S_CONFIG["enable_live_migration"] = enable_live_migration
    _K8S_CONFIG["enable_proactive_sla_migration"] = enable_proactive_sla_migration
    _K8S_CONFIG["enable_failure_prediction"] = enable_failure_prediction
    
    
    # ‚úÖ PROPAGATE: Configurar extens√µes
    from simulator.extensions.edge_server_extensions import configure_layer_download_strategy
    from simulator.extensions.service_extensions import configure_migration_strategy
    
    configure_layer_download_strategy(
        enable_p2p=enable_p2p,
        enable_registry=True
    )
    
    configure_migration_strategy(
        enable_live_migration=enable_live_migration,
        enable_state_transfer=True
    )
    
    print(f"\n[K8S_CONFIG] Kubernetes Enhancements Configured:")
    print(f"             - P2P Layer Download: {'ENABLED ‚úÖ' if enable_p2p else 'DISABLED ‚ùå'}")
    print(f"             - Live Migration: {'ENABLED ‚úÖ' if enable_live_migration else 'DISABLED ‚ùå'}")
    print(f"             - Proactive SLA Migration: {'ENABLED ‚úÖ' if enable_proactive_sla_migration else 'DISABLED ‚ùå'}")
    print(f"             - Baseline: {'NO' if any([enable_p2p, enable_live_migration, enable_proactive_sla_migration]) else 'YES (Standard Kubernetes)'}\n")
    print(f"             - Failure Prediction: {'ENABLED ‚úÖ' if enable_failure_prediction else 'DISABLED ‚ùå'}")

def get_kubernetes_config():
    """Retorna configura√ß√£o atual do Kubernetes."""
    global _K8S_CONFIG 
    return _K8S_CONFIG.copy()

# ============================================================================
# ‚úÖ SISTEMA DE M√âTRICAS DEDICADO DO KUBERNETES (Output Convergente)
# ============================================================================

# Estrutura espelho do TrustEdge para garantir compatibilidade do JSON
_k8s_metrics_store = {
    "total_provisionings": 0,
    "provisionings_finished": 0,
    "total_migrations": 0,
    "migrations_finished": 0,
    "migrations_interrupted": 0,
    # Mapeamento para garantir compara√ß√£o correta nos gr√°ficos
    "migrations_by_original_reason": {
        "server_failed_unpredicted": 0, # Mapeia para Reactive Pod Recreation
        "delay_violation": 0,           # Mapeia para Proactive Optimization
        "low_reliability": 0,           # N√£o usado no K8s (mas mantido para schema)
        "predicted_failure": 0,         # N√£o usado no K8s
    },
    "migration_times": {
        "all_migrations": [],
    }
}

def initialize_k8s_tracking():
    """Inicializa contadores exclusivos para a execu√ß√£o do Kubernetes."""
    global _k8s_metrics_store, _migration_counters
    
    # Resetar contadores granulares internos
    reset_migration_counters()
    
    # Resetar store de sa√≠da
    _k8s_metrics_store = {
        "total_provisionings": 0,
        "provisionings_finished": 0,
        "total_migrations": 0,
        "migrations_finished": 0,
        "migrations_interrupted": 0,
        "migrations_by_original_reason": {
            "server_failed_unpredicted": 0,
            "delay_violation": 0,
            "low_reliability": 0,
            "predicted_failure": 0,
        },
        "migration_times": {
            "all_migrations": [],
        }
    }

    _k8s_prediction_quality = {
        "proactive_migrations": [],
        "true_positives": 0,
        "false_positives": 0,
        "false_negatives": 0,
    }

def collect_k8s_final_metrics():
    """
    Consolida os contadores internos do Kubernetes (_migration_counters) 
    para o formato padr√£o de sa√≠da esperado pelos scripts de plotagem.
    """
    global _k8s_metrics_store, _migration_counters, _k8s_prediction_quality
    
    # 1. Migra√ß√µes Totais
    total_migs = _migration_counters["total"]
    
    # Debug expl√≠cito
    print(f"[DEBUG_METRICS] Total Migrations Interno: {total_migs}")
    
    _k8s_metrics_store["total_migrations"] = total_migs
    _k8s_metrics_store["migrations_finished"] = _migration_counters["successful"]
    _k8s_metrics_store["migrations_interrupted"] = _migration_counters["failed"]
    
    # 2. Breakdown por Raz√£o Dedu√ß√£o Matem√°tica
    proactive_count = _migration_counters["by_reason"].get("delay_violation", 0)
    calculated_reactive = total_migs - proactive_count
    if calculated_reactive < 0: calculated_reactive = 0
    
    # ‚úÖ ESTRAT√âGIA DE ALIASING PARA COMPATIBILIDADE DE SCRIPTS
    _k8s_metrics_store["migrations_by_original_reason"] = {
        # Chave Padr√£o TrustEdge (Que o script de compara√ß√£o provavelmente usa)
        "server_failed_unpredicted": calculated_reactive,
        
        # Chave Legacy/K8s (Que pode ser usada como fallback)
        "server_failed": calculated_reactive,
        
        # Chaves Proativas
        "delay_violation": proactive_count,
        "low_reliability": 0,    
        "predicted_failure": 0   
    }

    print(f"[DEBUG_METRICS] Exportando -> Reactive (Aliased): {calculated_reactive}, Proactive: {proactive_count}")
        
    # 3. Provisionamentos (Snapshot final)
    active_services = 0
    total_services = 0
    for user in User.all():
        for app in user.applications:
            total_services += 1
            if app.services[0].server:
                active_services += 1
    
    _k8s_metrics_store["total_provisionings"] = total_services
    _k8s_metrics_store["provisionings_finished"] = active_services
    
    pass

    print(f"[DEBUG_METRICS] Exportando -> Reactive: {calculated_reactive}, Proactive: {proactive_count}")
        
    tp = _k8s_prediction_quality["true_positives"]
    fp = _k8s_prediction_quality["false_positives"]
    fn = _k8s_prediction_quality["false_negatives"]
    
    precision = 0.0
    recall = 0.0
    
    if (tp + fp) > 0:
        precision = (tp / (tp + fp)) * 100
    
    if (tp + fn) > 0:
        recall = (tp / (tp + fn)) * 100
    
    _k8s_metrics_store["prediction_quality"] = {
        "precision": precision,
        "recall": recall,
        "true_positives": tp,
        "false_positives": fp,
        "false_negatives": fn,
        "total_proactive_migrations": len(_k8s_prediction_quality["proactive_migrations"]),
    }
    
    print(f"[K8S_METRICS] Qualidade Preditiva:")
    print(f"              - Precision: {precision:.2f}%")
    print(f"              - Recall: {recall:.2f}%")
    print(f"              - TP: {tp}, FP: {fp}, FN: {fn}")

def get_k8s_metrics_export():
    """Retorna c√≥pia das m√©tricas para exporta√ß√£o JSON."""
    return _k8s_metrics_store.copy()

def get_migration_counters():
    return _migration_counters

def reset_migration_counters():
    global _migration_counters
    _migration_counters = {
        "total": 0,
        "by_reason": {
            "server_failed": 0,
            "delay_violation": 0,
            "low_reliability": 0
        },
        "by_step": {},
        "successful": 0,
        "failed": 0,
        "conversions": {
            "live_to_cold": 0,           # Origem falhou durante Live
            "target_recovery": 0,         # Destino falhou, encontrou novo
            "orphan_recovery": 0,         # Ambos falharam, encontrou novo
            "emergency_recovery": 0,      # Recupera√ß√£o de emerg√™ncia
            "fake_live_migrations": 0,      # Recupera√ß√£o de emerg√™ncia
        },
        "failures": {
            "target_failed": 0,           # Destino falhou
            "origin_failed": 0,           # Origem falhou
            "both_failed": 0,             # Ambos falharam
            "no_recovery_possible": 0,    # Sem servidor dispon√≠vel
        }
    }

def increment_migration_counter(reason, current_step, success=True):
    """
    Incrementa contadores de migra√ß√£o de forma segura e centralizada.
    """
    global _migration_counters
    _migration_counters["total"] += 1
    
    # ‚úÖ CORRE√á√ÉO 1: Mapeamento de sinonimos para garantir consist√™ncia
    # O TrustEdge usa 'server_failed_unpredicted', o K8s usa 'server_failed'.
    # Vamos normalizar aqui ou garantir que a exporta√ß√£o trate isso.
    # Decis√£o: Manter 'server_failed' internamente e mapear na exporta√ß√£o.
    
    if reason not in _migration_counters["by_reason"]:
         # Inicializa se n√£o existir
        _migration_counters["by_reason"][reason] = 0
        
    _migration_counters["by_reason"][reason] += 1
    
    if current_step not in _migration_counters["by_step"]:
        _migration_counters["by_step"][current_step] = 0
    _migration_counters["by_step"][current_step] += 1
    
    if success:
        _migration_counters["successful"] += 1
        status_str = "‚úì SUCESSO"
    else:
        _migration_counters["failed"] += 1
        status_str = "‚úó FALHA"
    
    print(f"[K8S_RECREATE] Pod recreado #{_migration_counters['total']}")
    print(f"               Motivo: {reason}")
    print(f"               Step: {current_step}")
    print(f"               Status: {status_str}")

def print_migration_summary():
    counters = get_migration_counters()
    
    print(f"\n{'='*60}")
    print(f"RESUMO DE RECRIA√á√ïES DE PODS (Kubernetes Enhanced)")
    print(f"{'='*60}")
    print(f"Total de recria√ß√µes: {counters['total']}")
    print(f"Recria√ß√µes bem-sucedidas: {counters['successful']}")
    print(f"Recria√ß√µes mal-sucedidas: {counters['failed']}")
    
    if counters['total'] > 0:
        success_rate = (counters['successful'] / counters['total']) * 100
        print(f"Taxa de sucesso: {success_rate:.2f}%")
    
    print(f"\nRecria√ß√µes por motivo:")
    for reason, count in counters['by_reason'].items():
        if count > 0:
            percentage = (count / counters['total']) * 100
            print(f"  - {reason}: {count} ({percentage:.1f}%)")
    
    # ‚úÖ NOVO: Resumo de convers√µes e recupera√ß√µes
    conversions = counters.get("conversions", {})
    failures = counters.get("failures", {})
    
    total_conversions = sum(conversions.values())
    total_failures = sum(failures.values())
    
    if total_conversions > 0:
        print(f"\nConvers√µes e Recupera√ß√µes:")
        print(f"  - Live ‚Üí Cold (origem falhou): {conversions.get('live_to_cold', 0)}")
        print(f"  - Novo destino (target falhou): {conversions.get('target_recovery', 0)}")
        print(f"  - Recupera√ß√£o de √≥rf√£o: {conversions.get('orphan_recovery', 0)}")
        print(f"  - Recupera√ß√£o de emerg√™ncia: {conversions.get('emergency_recovery', 0)}")
        print(f"  TOTAL: {total_conversions}")
    
    if total_failures > 0:
        print(f"\nTipos de Falhas Durante Migra√ß√£o:")
        print(f"  - Destino falhou: {failures.get('target_failed', 0)}")
        print(f"  - Origem falhou: {failures.get('origin_failed', 0)}")
        print(f"  - Ambos falharam: {failures.get('both_failed', 0)}")
        print(f"  - Sem recupera√ß√£o poss√≠vel: {failures.get('no_recovery_possible', 0)}")
        print(f"  TOTAL: {total_failures}")
    
    print(f"{'='*60}\n")

# ============================================================================
# KUBERNETES QOS CLASSES (baseado em resource requests/limits)
# ============================================================================

def classify_qos(service):
    """
    Classifica pod em classes QoS REAIS do Kubernetes:
    - Guaranteed: requests = limits para todos os recursos
    - Burstable: requests < limits OU apenas requests definidos
    - BestEffort: sem requests ou limits
    
    Simula√ß√£o: baseado na raz√£o demand/capacity do servi√ßo
    """
    if not service:
        return "BestEffort"
    
    # Simular requests/limits baseado em demanda (usando helper functions)
    cpu_demand = get_normalized_demand(service)  # From helper_functions.py
    memory_demand = get_normalized_demand(service)  # Assumindo fun√ß√£o similar para mem√≥ria
    
    # Simular requests (70% da demanda) e limits (100% da demanda)
    cpu_requests = cpu_demand * 0.7
    cpu_limits = cpu_demand
    memory_requests = memory_demand * 0.7
    memory_limits = memory_demand
    
    # Verificar Guaranteed: requests == limits
    if cpu_requests == cpu_limits and memory_requests == memory_limits:
        return "Guaranteed"
    
    # Verificar BestEffort: sem demanda
    if cpu_demand == 0 and memory_demand == 0:
        return "BestEffort"
    
    # Caso padr√£o: Burstable
    return "Burstable"

def get_qos_priority(qos_class):
    """
    Retorna prioridade para eviction do Kubernetes:
    Guaranteed (3) > Burstable (2) > BestEffort (1)
    
    Durante resource pressure, Kubernetes evicta na ordem inversa.
    """
    priorities = {
        "Guaranteed": 3,
        "Burstable": 2,
        "BestEffort": 1
    }
    return priorities.get(qos_class, 0)

# ============================================================================
# KUBERNETES SCHEDULER (Filtering + Scoring)
# ============================================================================

def kubernetes_scheduler(service, user, application):
    """
    Implementa scheduler PADR√ÉO do Kubernetes (kube-scheduler) para EDGE:
    
    1. Filtering Phase (Predicates):
       - PodFitsResources: Node tem recursos suficientes
       - NodeCondition: Node est√° Ready
       
    2. Scoring Phase (Priorities):
       - NodeResourcesLeastAllocated (peso padr√£o: 1)
       - NodeResourcesBalancedAllocation (peso padr√£o: 1)
       
    ‚ùå REMOVIDO nesta vers√£o:
       - ImageLocality: N√£o aplic√°vel em edge geo-distribu√≠do (sem registry compartilhado)
       
    IMPORTANTE: 
    - Kubernetes padr√£o N√ÉO considera lat√™ncia/localiza√ß√£o!
    - Kubernetes padr√£o N√ÉO considera SLA de delay!
    - Para edge computing, seria necess√°rio custom scheduler (n√£o implementado aqui).
    """
    
    # 1. FILTERING PHASE
    feasible_nodes = filter_feasible_nodes(service, user, application)
    
    if not feasible_nodes:
        print(f"[K8S_SCHEDULER] Nenhum node vi√°vel para app {application.id}")
        return None
    
    # 2. SCORING PHASE
    scored_nodes = score_nodes_standard(feasible_nodes, service, user, application)
    
    # 3. BINDING PHASE
    best_node = max(scored_nodes, key=lambda x: x["score"])
    
    print(f"[K8S_SCHEDULER] App {application.id} ‚Üí Node {best_node['server'].id}")
    print(f"                Score: {best_node['score']:.2f}")
    print(f"                LeastAllocated: {best_node['least_allocated']:.3f}")
    print(f"                Balanced: {best_node['balanced']:.3f}")
    # ‚ùå REMOVIDO: print(f"                ImageLocality: {best_node['image_locality']:.3f}")
    
    return best_node["server"]

def filter_feasible_nodes(service, user, application):
    """
    Filtering Phase - Predicates do Kubernetes:
    
    1. PodFitsResources: Node tem CPU, mem√≥ria e disco suficientes
    2. NodeCondition: Node est√° Ready (status == 'available')
    3. NodeUnschedulable: Node n√£o est√° marcado como unschedulable
    
    Kubernetes N√ÉO filtra por lat√™ncia ou localiza√ß√£o!
    """
    feasible = []
    
    for server in EdgeServer.all():
        # Predicate: NodeCondition (node must be Ready)
        if server.status != "available":
            continue
        
        # Predicate: PodFitsResources
        if not server.has_capacity_to_host(service):
            continue
        
        # Node passou todos os predicates
        feasible.append(server)
    
    print(f"[K8S_FILTER] {len(feasible)}/{len(EdgeServer.all())} nodes vi√°veis")
    return feasible

def score_nodes_standard(nodes, service, user, application):
    """
    Scoring Phase - Priorities do Kubernetes PADR√ÉO (EDGE VERSION):
    
    Plugins ativos por padr√£o (todos com peso 1):
    1. NodeResourcesLeastAllocated: Favorece nodes com MAIS recursos livres
    2. NodeResourcesBalancedAllocation: Favorece nodes com uso balanceado
    
    ‚ùå REMOVIDO: ImageLocality
       Raz√£o: No edge computing geo-distribu√≠do, n√£o h√° registry compartilhado.
              Kubernetes padr√£o n√£o otimiza por cache de imagens em cen√°rios edge.
    
    IMPORTANTE: Kubernetes padr√£o N√ÉO considera lat√™ncia ou localiza√ß√£o!
    """
    scored_nodes = []
    
    for server in nodes:
        total_score = 0.0
        
        # 1. NodeResourcesLeastAllocated (peso: 1, normalizado 0-10)
        cpu_allocatable = server.cpu
        cpu_requested = server.cpu_demand
        cpu_score = ((cpu_allocatable - cpu_requested) / cpu_allocatable) * 10 if cpu_allocatable > 0 else 0
        
        memory_allocatable = server.memory
        memory_requested = server.memory_demand
        memory_score = ((memory_allocatable - memory_requested) / memory_allocatable) * 10 if memory_allocatable > 0 else 0
        
        least_allocated_score = (cpu_score + memory_score) / 2  # 0-10
        total_score += least_allocated_score
        
        # 2. NodeResourcesBalancedAllocation (peso: 1, normalizado 0-10)
        cpu_fraction = cpu_requested / cpu_allocatable if cpu_allocatable > 0 else 0
        memory_fraction = memory_requested / memory_allocatable if memory_allocatable > 0 else 0
        
        mean = (cpu_fraction + memory_fraction) / 2
        variance = ((cpu_fraction - mean) ** 2 + (memory_fraction - mean) ** 2) / 2
        
        balanced_score = 10 - (variance * 10)  # 0-10
        balanced_score = max(0, balanced_score)
        total_score += balanced_score
        
        # ‚ùå REMOVIDO: ImageLocality
        # Kubernetes padr√£o em edge N√ÉO otimiza por cache (sem registry compartilhado)
        
        # Score final: soma direta (0-20), normalizada para 0-100
        normalized_score = (total_score / 20) * 100  # ‚Üê CORRIGIDO: /20 ao inv√©s de /30
        
        scored_nodes.append({
            "server": server,
            "score": normalized_score,
            "least_allocated": least_allocated_score,
            "balanced": balanced_score,
            # ‚ùå REMOVIDO: "image_locality": image_score
        })
    
    return scored_nodes

# ============================================================================
# MAIN ALGORITHM
# ============================================================================

def kubernetes_inspired(parameters: dict = {}):
    global _raw_latencies, _k8s_total_execution_time 
    current_step = parameters.get("current_step")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # INICIALIZA√á√ÉO (PRIMEIRO STEP)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if current_step == 1:
            
        _raw_latencies = []
        _k8s_total_execution_time = 0.0
        initialize_k8s_tracking() 
        
        enable_p2p = parameters.get("enable_p2p", False)
        enable_live_migration = parameters.get("enable_live_migration", False)
        enable_proactive_sla_migration = parameters.get("enable_proactive_sla_migration", False)
        enable_failure_prediction = parameters.get("enable_failure_prediction", False)  # ‚úÖ NOVO
        
        configure_kubernetes_enhancements(
            enable_p2p=enable_p2p,
            enable_live_migration=enable_live_migration,
            enable_proactive_sla_migration=enable_proactive_sla_migration,
            enable_failure_prediction=enable_failure_prediction  # ‚úÖ NOVO
        )
        
        # ‚úÖ NOVO: Inicializar cache Weibull se predi√ß√£o habilitada
        if enable_failure_prediction:
            from simulator.helper_functions import reset_weibull_estimation_cache
            try:
                reset_weibull_estimation_cache()
                print(f"[K8S] ‚úÖ Weibull prediction cache initialized")
            except Exception as e:
                print(f"[K8S] ‚ö†Ô∏è Could not reset Weibull cache: {e}")
    step_start_time = time.process_time()
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # PIPELINE PRINCIPAL (TODOS OS STEPS)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # 1. Provisionar novas requisi√ß√µes
    provision_new_requests(current_step)
    
    # 2. Desprovisionar servi√ßos inativos (antes de atualizar delays)
    k8s_check_and_deprovision_inactive_services(current_step)
    
    # 3. ‚úÖ ATUALIZAR DELAYS ANTES DE VERIFICAR VIOLA√á√ïES
    update_application_delays(current_step)

    if current_step % 50 == 0:
        config = get_kubernetes_config()
        print(f"\n[K8S_DEBUG] Step {current_step}:")
        print(f"            enable_proactive_sla_migration = {config['enable_proactive_sla_migration']}")
        print(f"            _K8S_CONFIG = {_K8S_CONFIG}\n")
    
    # 4. Verificar viola√ß√µes de SLA (agora com delays atualizados!)
    check_and_migrate_sla_violations(current_step)

    k8s_proactive_failure_migration(current_step)
    
    # 5. Monitorar sa√∫de das migra√ß√µes
    monitor_migration_health_and_recover(current_step)
    
    # 6. Processar migra√ß√µes em andamento
    process_ongoing_kubernetes_migrations(current_step)
    
    # 7. Recrear pods de servidores falhados
    reactive_pod_recreation(current_step)
    
    # 8. Coletar lat√™ncias brutas (para CDF)
    for user in User.all():
        for app in user.applications:
            if is_user_accessing_application(user, app, current_step):
                app_id = str(app.id)
                if app_id in user.delays:
                    current_delay = user.delays[app_id]
                    if current_delay != float('inf') and current_delay > 0:
                        _raw_latencies.append(current_delay)
    
    # 9. M√©tricas de SLA e infraestrutura
    collect_sla_violations_for_current_step()
    collect_infrastructure_metrics_for_current_step()
    update_user_perceived_downtime_for_current_step(current_step)
    k8s_validate_predictions(current_step)
    
    step_duration = time.process_time() - step_start_time
    _k8s_total_execution_time += step_duration

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # EXPORTA√á√ÉO FINAL (√öLTIMO STEP)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if current_step == parameters.get("time_steps"):
        print(f"\n[K8S] ‚úÖ Simula√ß√£o conclu√≠da - Exportando resultados finais...")
        
        # ‚úÖ NOVO: Coletar m√©tricas locais
        collect_k8s_final_metrics()
        prov_mig_metrics = get_k8s_metrics_export()
        
        # Import Helper functions (SLA e Infra s√£o gen√©ricos, ok usar)
        from simulator.helper_functions import collect_all_sla_violations, collect_all_infrastructure_metrics
        sla_metrics = collect_all_sla_violations()
        infra_metrics = collect_all_infrastructure_metrics()
        
        migration_counters = get_migration_counters()
        config = get_kubernetes_config()
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # DETERMINAR SUFIXO DO ARQUIVO
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        p2p = config["enable_p2p"]
        live = config["enable_live_migration"]
        sla = config["enable_proactive_sla_migration"]
        
        # ‚úÖ LOG: Mostrar configura√ß√£o detectada
        print(f"\n[K8S] üîç Configura√ß√£o detectada:")
        print(f"      P2P: {'ON' if p2p else 'OFF'}")
        print(f"      Live Migration: {'ON' if live else 'OFF'}")
        print(f"      Proactive SLA: {'ON' if sla else 'OFF'}")
        
        # ‚úÖ DETERMINAR SUFIXO (verificar combina√ß√µes COMPLETAS primeiro!)
        if p2p and live and sla:
            config_suffix = "_p2p_live_sla"
        elif p2p and live:
            config_suffix = "_p2p_live"
        elif p2p and sla:
            config_suffix = "_p2p_sla"
        elif live and sla:
            config_suffix = "_live_sla"
        elif p2p:
            config_suffix = "_p2p"
        elif live:
            config_suffix = "_live"
        elif sla:
            config_suffix = "_sla"
        else:
            config_suffix = "_baseline"
        
        print(f"      Sufixo do arquivo: {config_suffix}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ESTRUTURA DE RESULTADOS (ID√äNTICA AO TRUSTEDGE)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        total_steps = parameters.get("time_steps", 1)
        avg_time_per_step_ms = (_k8s_total_execution_time / total_steps) * 1000
        
        results = {
            "algorithm": f"Kubernetes{config_suffix.replace('_', ' ').title()}",
            "configuration": config,
            
            "sla": {
                "total_delay_sla_violations": sla_metrics.get("total_delay_sla_violations", 0),
                "total_perceived_downtime": sla_metrics.get("total_perceived_downtime", 0),
                "total_downtime_sla_violations": sla_metrics.get("total_downtime_sla_violations", 0),
                "avg_delay": sla_metrics.get("average_delay", 0) if "average_delay" in sla_metrics else (sum(_raw_latencies) / len(_raw_latencies) if _raw_latencies else 0),
                "exec_overhead_ms": avg_time_per_step_ms,
            },
            
            "infrastructure": {
                "average_overall_occupation": infra_metrics.get("average_overall_occupation", 0),
                "total_power_consumption": infra_metrics.get("total_power_consumption", 0),
            },
            
            "provisioning_and_migration": {
                "total_provisionings": prov_mig_metrics.get("total_provisionings", 0),
                "total_migrations": prov_mig_metrics.get("total_migrations", 0),
                "migrations_finished": prov_mig_metrics.get("migrations_finished", 0),
                "migrations_interrupted": prov_mig_metrics.get("migrations_interrupted", 0),
                
                # Mapeamento do dicion√°rio local para o JSON
                "migrations_by_reason": prov_mig_metrics.get("migrations_by_original_reason", {}),
                
                # Breakdown reativo
                "server_failed_breakdown": {
                     "cold_migrations": migration_counters["by_reason"].get("server_failed", 0),
                     "hot_migrations": 0 # K8s reactive √© sempre cold start
                },
                
                "avg_migration_time": 0, # Opcional ou calcular
                "downtime_breakdown": {}, # Deixar vazio ou preencher se rastrear
            },
            
            "raw_latencies": _raw_latencies,
            "total_latency_samples": len(_raw_latencies),
            
            "legacy_metrics": {
                "total_migrations": migration_counters["total"],
                "migrations_successful": migration_counters["successful"],
                "migrations_failed": migration_counters["failed"],
                "migrations_by_reason": migration_counters["by_reason"],
            },
            
            "prediction_quality": _k8s_metrics_store.get("prediction_quality", {
                "precision": 0,
                "recall": 0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 0,
            }),

            "execution": {
                "avg_time_per_step_seconds": _k8s_total_execution_time / total_steps,
            },

            "simulation_steps": parameters.get("time_steps", 0),
        }
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # SALVAR ARQUIVO JSON
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        import os
        import json
        
        os.makedirs("results", exist_ok=True)
        run_id = parameters.get("run_id")
        if run_id is not None:
            output_file = f"results/metrics_run_{run_id}.json"
        else:
            output_file = f"results/k8s{config_suffix}_results.json"
        
        with open(output_file, "w") as f:
            json.dump(results, f, indent=2)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # LOG FINAL
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        print("\n" + "="*70)
        print(f"‚úÖ [PAPER] Resultados Kubernetes{config_suffix.replace('_', ' ').title()} exportados")
        print(f"   Arquivo: {output_file}")
        print(f"   Configura√ß√£o: P2P={'ON' if p2p else 'OFF'} | Live={'ON' if live else 'OFF'} | SLA={'ON' if sla else 'OFF'}")
        print(f"   Downtime Total: {sla_metrics.get('total_perceived_downtime', 0)} steps")
        print(f"   SLA Violations: {sla_metrics.get('total_delay_sla_violations', 0)}")
        print(f"   Lat√™ncias coletadas: {len(_raw_latencies)}")
        print(f"   Migra√ß√µes totais: {prov_mig_metrics.get('total_migrations', 0)}")
        print(f"   Migra√ß√µes finalizadas: {prov_mig_metrics.get('migrations_finished', 0)}")
        print("="*70 + "\n")
        
        print_migration_summary()

# ============================================================================
# FUN√á√ïES HELPER PARA C√ÅLCULO DE M√âTRICAS
# ============================================================================

def calculate_total_downtime():
    """
    Calcula downtime total percebido pelos usu√°rios.
    Usa a mesma l√≥gica do TrustEdge mas localmente.
    """
    total_downtime = 0
    
    for user in User.all():
        for app in user.applications:
            app_id = str(app.id)
            
            # Acessar hist√≥rico de downtime do usu√°rio
            if hasattr(user, 'downtime_history') and app_id in user.downtime_history:
                app_downtime = sum(user.downtime_history[app_id])
                total_downtime += app_downtime
    
    return total_downtime

def calculate_total_sla_violations():
    """
    Calcula total de viola√ß√µes de SLA de lat√™ncia.
    Usa a mesma l√≥gica do TrustEdge mas localmente.
    """
    total_violations = 0
    
    for user in User.all():
        for app in user.applications:
            app_id = str(app.id)
            
            # Verificar se aplica√ß√£o tem SLA de delay definido
            if hasattr(app, 'delay_sla') and app.delay_sla:
                delay_sla = app.delay_sla
                
                # Pegar delay atual
                if app_id in user.delays:
                    current_delay = user.delays[app_id]
                    
                    # Verificar viola√ß√£o
                    if current_delay > delay_sla and current_delay != float('inf'):
                        total_violations += 1
    
    return total_violations

# ============================================================================
# REACTIVE POD RECREATION (n√£o √© migra√ß√£o, √© recrea√ß√£o)
# ============================================================================

def reactive_pod_recreation(current_step):
    """
    Simula o comportamento padr√£o do Kubernetes de recriar pods quando um node falha.
    """
    print(f"\n[K8S] === VERIFICA√á√ÉO DE NODE FAILURES (REACTIVE) - STEP {current_step} ===")
    
    # Identificar servi√ßos em servidores falhados
    services_to_recover = []
    
    for service in Service.all():
        if service.server and not service.server.available:
            services_to_recover.append(service)
    
    if not services_to_recover:
        return

    # ‚úÖ CORRE√á√ÉO: Rastrear servidores j√° contabilizados como FN
    if _K8S_CONFIG.get('enable_failure_prediction', False):
        global _k8s_prediction_quality
        
        # ‚úÖ NOVO: Set para evitar duplica√ß√£o
        failed_servers_seen = set()
        
        for service in services_to_recover:
            failed_server = service.server
            
            # ‚úÖ CORRE√á√ÉO: Pular se j√° contabilizamos este servidor
            if failed_server.id in failed_servers_seen:
                continue
            
            failed_servers_seen.add(failed_server.id)
            
            # Verificar se essa falha foi prevista
            was_predicted = any(
                item["server_id"] == failed_server.id and not item.get("validated", False)
                for item in _k8s_prediction_quality["proactive_migrations"]
            )
            
            if not was_predicted:
                # FALSE NEGATIVE: Servidor falhou mas n√£o previmos
                _k8s_prediction_quality["false_negatives"] += 1
                
                print(f"[K8S_VALIDATE] ‚ö†Ô∏è FN: Server {failed_server.id} falhou sem previs√£o "
                      f"(step {current_step})")

    print(f"[K8S] {len(services_to_recover)} servi√ßos perderam seus nodes. Iniciando recria√ß√£o...")

    for service in services_to_recover:
        user = service.application.users[0]
        app = service.application
        failed_server = service.server
        
        print(f"[K8S] Servi√ßo {service.id} (App {app.id}) estava no servidor {failed_server.id} (FALHOU)")
        
        # Kubernetes Scheduler Logic: Escolher node com recursos dispon√≠veis
        candidates = [s for s in EdgeServer.all() if s.status == "available" and s.has_capacity_to_host(service)]
        
        if candidates:
            # ‚úÖ CORRE√á√ÉO 1: Passar 'user' e 'app' que faltavam (causava o TypeError)
            scored_candidates = score_nodes_standard(candidates, service, user, app)
            
            # ‚úÖ CORRE√á√ÉO 2: Selecionar o servidor do dicion√°rio de score (causava erro de provision)
            best_node_data = max(scored_candidates, key=lambda x: x["score"])
            target_server = best_node_data["server"]
            
            try:
                # Provisionar no novo servidor (Cold Migration for√ßada)
                service.provision(target_server=target_server)
                
                # ‚úÖ GARANTIA DE METADADOS
                if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                    migration = service._Service__migrations[-1]
                    
                    migration["migration_reason"] = "server_failed"
                    migration["original_migration_reason"] = "server_failed" # CR√çTICO PARA O RELAT√ìRIO
                    migration["is_cold_migration"] = True
                    
                    if migration.get("origin") is None:
                         migration["origin"] = failed_server
                
                # Atualizar delays para refletir novo posicionamento
                user.set_communication_path(app=app)
                new_delay = user._compute_delay(app=app, metric="latency")
                user.delays[str(app.id)] = new_delay
                
                print(f"[K8S] ‚úì Novo pod criado no node {target_server.id}")
                increment_migration_counter("server_failed", current_step, success=True)
                print(f"      Delay resultante: {new_delay:.2f}ms")
                    
            except Exception as e:
                print(f"[K8S] ‚úó Erro ao recriar pod: {e}")
                import traceback
                traceback.print_exc()
                increment_migration_counter("server_failed", current_step, success=False)
                
                if target_server and hasattr(target_server, 'ongoing_migrations'):
                    target_server.ongoing_migrations -= 1
                
        else:
            print(f"[K8S] ‚úó Nenhum node dispon√≠vel para recriar pod")
            increment_migration_counter("server_failed", current_step, success=False)

    print(f"[K8S] === FIM VERIFICA√á√ÉO DE NODE FAILURES ===\n")


# ============================================================================
# PREDI√á√ÉO DE FALHAS PARA KUBERNETES ENHANCED
# ============================================================================

def k8s_proactive_failure_migration(current_step):
    if not _K8S_CONFIG.get('enable_failure_prediction', False):
        return
    
    # ‚úÖ LOGGING DETALHADO A CADA 100 STEPS
    if current_step % 100 == 0:
        print(f"\n[K8S_PREDICT] === DIAGN√ìSTICO STEP {current_step} ===")
    
    RELIABILITY_THRESHOLD = 50.0  # ‚Üê Reduzido
    PREDICTION_HORIZON = 300
    
    migrations_triggered = 0
    servers_checked = 0
    servers_skipped = {
        "no_server": 0,
        "server_unavailable": 0,
        "in_migration": 0,
        "no_weibull_params": 0,
        "reliability_above_threshold": 0,
        "no_predictions": 0,
        "no_viable_target": 0,
    }
    
    for service in Service.all():
        if not service.server:
            servers_skipped["no_server"] += 1
            continue
        
        if not service.server.available:
            servers_skipped["server_unavailable"] += 1
            continue
        
        if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
            last_migration = service._Service__migrations[-1]
            if last_migration.get("end") is None:
                servers_skipped["in_migration"] += 1
                continue
        
        server = service.server
        servers_checked += 1
        
        # ‚úÖ VERIFICAR HIST√ìRICO
        if hasattr(server, 'failure_model') and hasattr(server.failure_model, 'failure_history'):
            history_len = len(server.failure_model.failure_history)
            if history_len < 3:
                servers_skipped["no_weibull_params"] += 1
                if current_step % 100 == 0:
                    print(f"[K8S_PREDICT] Server {server.id}: Hist√≥rico insuficiente ({history_len} falhas)")
                continue
        else:
            servers_skipped["no_weibull_params"] += 1
            continue
        
        from simulator.helper_functions import (
            get_server_conditional_reliability_weibull,
            predict_next_n_failures,
        )
        
        try:
            reliability = get_server_conditional_reliability_weibull(server, PREDICTION_HORIZON)
        except Exception as e:
            servers_skipped["no_weibull_params"] += 1
            if current_step % 100 == 0:
                print(f"[K8S_PREDICT] ‚ö†Ô∏è Erro Weibull Server {server.id}: {e}")
            continue
        
        if reliability >= RELIABILITY_THRESHOLD:
            servers_skipped["reliability_above_threshold"] += 1
            continue
        
        predictions = predict_next_n_failures(server, n_failures=2, max_horizon=PREDICTION_HORIZON)
        
        if not predictions:
            servers_skipped["no_predictions"] += 1
            continue
        
        # ‚úÖ LOGGING: Servidor eleg√≠vel para migra√ß√£o
        if current_step % 100 == 0:
            print(f"[K8S_PREDICT] ‚úÖ Server {server.id}: reliability={reliability:.1f}%, {len(predictions)} falhas previstas")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # DECIS√ÉO K8S: Scheduler PADR√ÉO para escolher destino
        # (SEM trust_cost, SEM SLA awareness, SEM STAY vs GO)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        app = service.application
        user = app.users[0] if app.users else None
        
        if not user or not is_user_accessing_application(user, app, current_step):
            continue
        
        # Usar scheduler K8s padr√£o (CPU/RAM only)
        target = kubernetes_scheduler(service, user, app)
        
        if not target or target.id == server.id:
            print(f"[K8S_PREDICT] ‚ùå Sem destino vi√°vel para service {service.id}")
            continue
        
        global _k8s_prediction_quality
        _k8s_prediction_quality["proactive_migrations"].append({
            "service_id": service.id,
            "server_id": server.id,
            "step": current_step,
            "reason": "predicted_failure",
            "validated": False,
            "validation_window": PREDICTION_HORIZON,  # 100 steps
            "deadline": current_step + PREDICTION_HORIZON,
            "reliability_at_prediction": reliability,
            "predictions_count": len(predictions),
        })

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # EXECUTAR MIGRA√á√ÉO (Live ou Cold conforme config)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        use_live = _K8S_CONFIG['enable_live_migration']
        origin_server = service.server
        
        try:
            if use_live:
                service._available = True
                service._migration_reason = "predicted_failure"
                target.ongoing_migrations += 1
                service.provision(target_server=target)

                if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                    migration = service._Service__migrations[-1]
                    migration["migration_reason"] = "predicted_failure"
                    migration["original_migration_reason"] = "predicted_failure"
                    migration["is_cold_migration"] = False
                    migration["origin"] = origin_server
                    migration["target"] = target
                    migration["is_proactive"] = True
                    migration["relationships_created_by_algorithm"] = True
                    migration["k8s_prediction_data"] = {
                        "reliability": reliability,
                        "threshold": RELIABILITY_THRESHOLD,
                        "predictions": len(predictions),
                    }
            else:
                service._available = False
                service._migration_reason = "predicted_failure"
                target.ongoing_migrations += 1
                service.provision(target_server=target)
                
                if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                    migration = service._Service__migrations[-1]
                    migration["migration_reason"] = "predicted_failure"
                    migration["original_migration_reason"] = "predicted_failure"
                    migration["is_cold_migration"] = True
                    migration["origin"] = origin_server
                    migration["target"] = target
                    migration["is_proactive"] = True
            
            increment_migration_counter("predicted_failure", current_step, success=True)
            migrations_triggered += 1
            
            print(f"[K8S_PREDICT] ‚úÖ Migra√ß√£o proativa: Service {service.id} ‚Üí Server {target.id}")
            
        except Exception as e:
            print(f"[K8S_PREDICT] ‚ùå Erro ao migrar service {service.id}: {e}")
            if target and hasattr(target, 'ongoing_migrations'):
                target.ongoing_migrations = max(0, target.ongoing_migrations - 1)
            increment_migration_counter("predicted_failure", current_step, success=False)
    
    if current_step % 100 == 0:
        print(f"[K8S_PREDICT] Servidores verificados: {servers_checked}")
        print(f"[K8S_PREDICT] Migra√ß√µes disparadas: {migrations_triggered}")
        print(f"[K8S_PREDICT] Raz√µes de exclus√£o:")
        for reason, count in servers_skipped.items():
            if count > 0:
                print(f"              - {reason}: {count}")
        print(f"[K8S_PREDICT] === FIM DIAGN√ìSTICO ===\n")


def process_ongoing_kubernetes_migrations(current_step):
    """
    Processa migra√ß√µes em andamento do Kubernetes.
    
    IMPORTANTE: Necess√°rio para decrementar contadores e finalizar migra√ß√µes.
    ‚úÖ CORRE√á√ÉO: Processar TODOS os tipos de migra√ß√£o (n√£o apenas server_failed).
    """
    migrations_completed = 0
    migrations_failed = 0
    
    for service in Service.all():
        if not hasattr(service, '_Service__migrations') or len(service._Service__migrations) == 0:
            continue
        
        migration = service._Service__migrations[-1]
        
        # Pular migra√ß√µes j√° finalizadas
        if migration.get("end") is not None:
            continue
        
        # ‚úÖ CORRE√á√ÉO: REMOVER filtro que exclui delay_violation
        # ANTES: if migration.get("migration_reason") != "server_failed": continue
        # DEPOIS: Processar TODAS as migra√ß√µes
        
        status = migration.get("status", "unknown")
        target = migration.get("target")
        is_live = not migration.get("is_cold_migration", False)
        migration_reason = migration.get("migration_reason", "unknown")
        
        # ‚úÖ Verificar se migra√ß√£o foi completada
        if status == "finished":
            migrations_completed += 1
            
            # Decrementar contador do servidor de destino
            if target and hasattr(target, 'ongoing_migrations'):
                target.ongoing_migrations = max(0, target.ongoing_migrations - 1)
            
            migration_type = "Live" if is_live else "Cold"
            print(f"[K8S_MIG] ‚úÖ Migra√ß√£o {migration_type} completada: Service {service.id} ‚Üí Server {target.id} (Motivo: {migration_reason})")
        
        # ‚úÖ Verificar se falhou (servidor de destino falhou)
        elif target and not target.available:
            migration["end"] = current_step
            migration["status"] = "interrupted"
            migration["interruption_reason"] = "target_server_failed"
            
            migrations_failed += 1
            
            if target and hasattr(target, 'ongoing_migrations'):
                target.ongoing_migrations = max(0, target.ongoing_migrations - 1)
            
            print(f"[K8S_MIG] ‚ùå Migra√ß√£o falhou: Service {service.id} (target falhou, motivo original: {migration_reason})")
    
    if migrations_completed > 0 or migrations_failed > 0:
        print(f"[K8S_MIG] Migra√ß√µes processadas: {migrations_completed} completas, {migrations_failed} falhadas")



# ============================================================================
# PROVISIONING (scheduling acontece APENAS aqui)
# ============================================================================

def provision_new_requests(current_step):
    """
    Provisiona novos pods.
    
    Kubernetes PADR√ÉO:
    - Scheduling acontece apenas na cria√ß√£o do pod
    - Decis√£o √© permanente at√© pod ser deletado
    - SEM rebalanceamento autom√°tico
    - SEM otimiza√ß√£o cont√≠nua
    """
    print(f"\n[K8S] === SCHEDULING DE NOVOS PODS - STEP {current_step} ===")
    
    apps_to_provision = []
    
    for user in User.all():
        if is_making_request(user, current_step):
            for app in user.applications:
                service = app.services[0]
                qos_class = classify_qos(service)
                
                apps_to_provision.append({
                    "application": app,
                    "user": user,
                    "service": service,
                    "qos_class": qos_class,
                    "qos_priority": get_qos_priority(qos_class)
                })
    
    if not apps_to_provision:
        print(f"[K8S] Nenhum novo pod para provisionar")
        return
    
    # Ordenar por QoS priority
    apps_to_provision.sort(key=lambda x: x["qos_priority"], reverse=True)
    
    print(f"[K8S] {len(apps_to_provision)} novos pods para provisionar")
    
    for item in apps_to_provision:
        app = item["application"]
        user = item["user"]
        service = item["service"]
        qos_class = item["qos_class"]
        
        print(f"\n[K8S] Scheduling pod {service.id} (QoS: {qos_class})")
        
        # Usar scheduler padr√£o do Kubernetes
        target_server = kubernetes_scheduler(service, user, app)
        
        if target_server:
            service.provision(target_server=target_server)
            
            user.set_communication_path(app=app)
            new_delay = user._compute_delay(app=app, metric="latency")
            user.delays[str(app.id)] = new_delay
            
            print(f"[K8S] ‚úì Pod criado no node {target_server.id}")
            print(f"      Delay resultante: {new_delay:.2f}ms")
            print(f"      AVISO: Pod permanecer√° neste node at√© ser deletado")
        else:
            print(f"[K8S] ‚úó Nenhum node dispon√≠vel - pod fica Pending")
    
    print(f"[K8S] === FIM SCHEDULING DE NOVOS PODS ===\n")

def update_application_delays(current_step):
    """
    Atualiza delays de TODAS as aplica√ß√µes ativas.
    
    ‚úÖ CORRE√á√ÉO: Atualizar mesmo se is_making_request() for True.
    """
    
    # ‚úÖ ADICIONAR: Contadores de debug
    delays_updated = 0
    delays_set_to_inf = 0
    delays_skipped = 0
    sample_delays = []  # Amostra para debug
    
    for user in User.all():
        for app in user.applications:
            service = app.services[0]
            app_id = str(app.id)
            
            if is_user_accessing_application(user, app, current_step):
                if service.server and service.server.status == "available" and service._available:
                    user.set_communication_path(app=app)
                    new_delay = user._compute_delay(app=app, metric="latency")
                    user.delays[app_id] = new_delay
                    delays_updated += 1
                    
                    # ‚úÖ ADICIONAR: Coletar amostra para debug
                    if len(sample_delays) < 5:  # Primeiros 5
                        sla = getattr(app, 'delay_sla', None)
                        sample_delays.append({
                            'app_id': app.id,
                            'delay': new_delay,
                            'sla': sla,
                            'violated': new_delay > sla if sla else False
                        })
                else:
                    # Servi√ßo indispon√≠vel
                    user.delays[app_id] = float('inf')
                    delays_set_to_inf += 1
            else:
                delays_skipped += 1
    
    # ‚úÖ ADICIONAR: LOG a cada 50 steps
    if current_step % 50 == 0:
        print(f"\n[K8S_DELAYS] Step {current_step}:")
        print(f"             - Delays atualizados: {delays_updated}")
        print(f"             - Setados para inf: {delays_set_to_inf}")
        print(f"             - N√£o acessando: {delays_skipped}")
        
        if sample_delays:
            print(f"\n[K8S_DELAYS] üîç Amostra de delays (primeiros 5):")
            for i, d in enumerate(sample_delays):
                sla_str = f"{d['sla']:.2f}ms" if d['sla'] else "SEM SLA"
                status = "VIOLADO ‚ùå" if d['violated'] else "OK ‚úÖ"
                print(f"             {i+1}. App {d['app_id']}: {d['delay']:.2f}ms / SLA={sla_str} [{status}]")

def get_active_applications_with_remaining_time(user, current_step):
    """Retorna aplica√ß√µes ativas com informa√ß√µes de tempo."""
    active_applications = []
    
    for application in user.applications:
        if is_user_accessing_application(user, application, current_step):
            app_id = str(application.id)
            last_access = user.access_patterns[app_id].history[-1]
            remaining_time = last_access["end"] - current_step
            
            active_applications.append({
                "application": application,
                "remaining_time": remaining_time,
                "total_duration": last_access["duration"],
                "access_start": last_access["start"],
                "access_end": last_access["end"]
            })
    
    return active_applications


def check_and_migrate_sla_violations(current_step):
    """
    ‚úÖ NOVA ESTRAT√âGIA: Migra√ß√£o Proativa para OTIMIZA√á√ÉO de Desempenho
    
    Migra quando:
    1. Existe servidor com delay >= 15% MELHOR que atual
    2. Servidor tem capacidade dispon√≠vel
    3. Minimiza downtime percebido
    
    IMPORTANTE: 
    - N√ÉO espera viola√ß√£o de SLA
    - Migra SEMPRE que houver oportunidade de melhoria significativa
    - Usa limiar de 15% para evitar migra√ß√µes triviais
    """
    
    if not _K8S_CONFIG['enable_proactive_sla_migration']:
        return
    
    print(f"\n[K8S_OPT] === VERIFICA√á√ÉO DE OTIMIZA√á√ÉO DE DESEMPENHO - STEP {current_step} ===")
    
    apps_checked = 0
    migrations_triggered = 0
    
    # ‚úÖ PAR√ÇMETRO: Limiar de melhoria m√≠nima para migra√ß√£o (15%)
    IMPROVEMENT_THRESHOLD = 0.15  # 15% de melhoria m√≠nima
    
    for user in User.all():
        active_applications = get_active_applications_with_remaining_time(user, current_step)
        
        for app_info in active_applications:
            app = app_info["application"]
            service = app.services[0]
            
            apps_checked += 1
            
            # PR√â-REQUISITO 1: Servidor atual deve estar dispon√≠vel
            if not service.server or service.server.status != "available":
                continue
            
            # PR√â-REQUISITO 2: N√£o h√° migra√ß√£o em andamento
            if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                last_migration = service._Service__migrations[-1]
                if last_migration.get("end") is None:
                    continue
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # BUSCAR SERVIDOR MELHOR (delay X% menor)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            app_id = str(app.id)
            current_delay = user.delays.get(app_id, float('inf'))
            
            # Pular se delay atual √© infinito (servi√ßo indispon√≠vel)
            if current_delay == float('inf'):
                continue
            
            # Pular se delay atual √© muito baixo (< 10ms) - sem ganho significativo
            if current_delay < 10:
                continue
            
            # Procurar servidor com delay significativamente MELHOR
            best_server, best_delay = find_significantly_better_server(
                service, user, app, current_delay, IMPROVEMENT_THRESHOLD
            )
            
            if not best_server:
                continue  # Nenhum servidor melhor encontrado
            
            # N√£o migrar se for o mesmo servidor
            if best_server.id == service.server.id:
                continue
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # CALCULAR GANHO DE DESEMPENHO
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            delay_reduction = current_delay - best_delay
            improvement_pct = (delay_reduction / current_delay) * 100
            
            print(f"\n[K8S_OPT] üéØ Oportunidade de otimiza√ß√£o detectada:")
            print(f"          App: {app.id}, User: {user.id}")
            print(f"          Servidor atual: {service.server.id} (delay: {current_delay:.2f}ms)")
            print(f"          Servidor melhor: {best_server.id} (delay: {best_delay:.2f}ms)")
            print(f"          Melhoria: {delay_reduction:.2f}ms ({improvement_pct:.1f}%)")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # INICIAR MIGRA√á√ÉO DE OTIMIZA√á√ÉO
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            try:
                origin_server = service.server  # Origem EST√Å VIVA (otimiza√ß√£o)
                
                # Decidir tipo de migra√ß√£o
                use_live_migration = _K8S_CONFIG['enable_live_migration']
                
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                # LIVE MIGRATION (se habilitado)
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                if use_live_migration:
                    print(f"[K8S_OPT] üîÑ Iniciando LIVE Migration para OTIMIZA√á√ÉO")
                    print(f"          Origem: {origin_server.id} (VIVA)")
                    print(f"          Destino: {best_server.id}")

                    # ‚ùå REMOVER mudan√ßa prematura
                    # service.server = best_server
                    # if service not in best_server.services:
                    #     best_server.services.append(service)

                    service._available = True
                    service._migration_reason = "delay_violation"

                    best_server.ongoing_migrations += 1
                    service.provision(target_server=best_server)

                    if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                        migration = service._Service__migrations[-1]
                        migration["migration_reason"] = "delay_violation"
                        migration["original_migration_reason"] = "delay_violation"
                        migration["is_proactive"] = True
                        migration["is_cold_migration"] = False
                        migration["origin"] = origin_server
                        migration["target"] = best_server
                        migration["relationships_created_by_algorithm"] = True

                    # ‚ùå REMOVER atualiza√ß√£o manual de delay
                    # user.set_communication_path(app=app)
                    # new_delay = user._compute_delay(app=app, metric="latency")
                    # user.delays[app_id] = new_delay

                    print(f"[K8S_OPT] ‚úÖ Live Migration iniciada (OTIMIZA√á√ÉO)")
                    increment_migration_counter("delay_violation", current_step, success=True)
                    migrations_triggered += 1
                
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                # COLD MIGRATION (padr√£o)
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                else:
                    print(f"[K8S_OPT] üîÑ Iniciando COLD Migration para OTIMIZA√á√ÉO")
                    print(f"          Origem: {origin_server.id}")
                    print(f"          Destino: {best_server.id}")
                    
                    # Marcar como indispon√≠vel
                    service._available = False
                    service._migration_reason = "delay_violation"
                    best_server.ongoing_migrations += 1
                    service.provision(target_server=best_server)

                    if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                        migration = service._Service__migrations[-1]
                        migration["migration_reason"] = "delay_violation"
                        migration["original_migration_reason"] = "delay_violation"
                        migration["is_cold_migration"] = True
                        migration["origin"] = origin_server
                        migration["target"] = best_server
                        migration["is_proactive"] = True
                        migration["optimization_metrics"] = {
                            "current_delay": current_delay,
                            "expected_delay": best_delay,
                            "improvement_ms": delay_reduction,
                            "improvement_pct": improvement_pct
                        }

                    # ‚ùå REMOVER atualiza√ß√£o manual de delay
                    # user.set_communication_path(app=app)
                    # new_delay = user._compute_delay(app=app, metric="latency")
                    # user.delays[app_id] = new_delay

                    print(f"[K8S_OPT] ‚úÖ Cold Migration iniciada (OTIMIZA√á√ÉO)")
                    increment_migration_counter("delay_violation", current_step, success=True)
                    migrations_triggered += 1
                    
            except Exception as e:
                print(f"[K8S_OPT] ‚ùå Erro ao migrar: {e}")
                import traceback
                traceback.print_exc()
                
                if best_server and hasattr(best_server, 'ongoing_migrations'):
                    best_server.ongoing_migrations -= 1
                increment_migration_counter("delay_violation", current_step, success=False)
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # RESUMO
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    if migrations_triggered > 0:
        print(f"\n[K8S_OPT] ‚úÖ {migrations_triggered} migra√ß√µes de otimiza√ß√£o iniciadas")
    else:
        print(f"\n[K8S_OPT] ‚ÑπÔ∏è Nenhuma oportunidade de otimiza√ß√£o encontrada")
    
    print(f"[K8S_OPT] üìä Estat√≠sticas:")
    print(f"          - Aplica√ß√µes verificadas: {apps_checked}")
    print(f"          - Migra√ß√µes disparadas: {migrations_triggered}")
    print(f"          - Limiar de melhoria: {IMPROVEMENT_THRESHOLD*100:.0f}%")
    
    print(f"[K8S_OPT] === FIM VERIFICA√á√ÉO DE OTIMIZA√á√ÉO ===\n")


def find_significantly_better_server(service, user, app, current_delay, improvement_threshold):
    """
    Encontra servidor com delay SIGNIFICATIVAMENTE MELHOR que atual.
    
    Args:
        service: Servi√ßo a ser migrado
        user: Usu√°rio acessando
        app: Aplica√ß√£o
        current_delay: Delay atual em ms
        improvement_threshold: Melhoria m√≠nima necess√°ria (ex: 0.15 = 15%)
    
    Returns:
        (EdgeServer, float): Melhor servidor e seu delay, ou (None, inf)
    """
    best_server = None
    best_delay = float('inf')
    
    # Calcular delay m√≠nimo necess√°rio para migra√ß√£o
    max_acceptable_delay = current_delay * (1 - improvement_threshold)
    
    candidates_evaluated = 0
    
    for server in EdgeServer.all():
        # 1. Servidor deve estar dispon√≠vel
        if server.status != "available":
            continue
        
        # 2. Servidor deve ter capacidade
        if not server.has_capacity_to_host(service):
            continue
        
        # 3. Pular servidor atual
        if server.id == service.server.id:
            continue
        
        candidates_evaluated += 1
        
        # 4. Calcular delay se servi√ßo estivesse neste servidor
        original_server = service.server
        service.server = server
        
        user.set_communication_path(app=app)
        predicted_delay = user._compute_delay(app=app, metric="latency")
        
        # Restaurar servidor original
        service.server = original_server
        
        # 5. Verificar se melhoria √© significativa
        if predicted_delay >= max_acceptable_delay:
            continue  # Melhoria insuficiente
        
        # 6. Escolher servidor com MENOR delay
        if predicted_delay < best_delay:
            best_delay = predicted_delay
            best_server = server
    
    if best_server:
        improvement = current_delay - best_delay
        improvement_pct = (improvement / current_delay) * 100
        
        print(f"[K8S_OPT] üîç Melhor servidor encontrado:")
        print(f"          Servidor: {best_server.id}")
        print(f"          Delay atual: {current_delay:.2f}ms")
        print(f"          Delay esperado: {best_delay:.2f}ms")
        print(f"          Melhoria: {improvement:.2f}ms ({improvement_pct:.1f}%)")
        print(f"          Candidatos avaliados: {candidates_evaluated}")
    
    return best_server, best_delay


def monitor_migration_health_and_recover(current_step):
    """
    Monitora sa√∫de de origem e destino durante migra√ß√µes em andamento.
    
    ‚úÖ CORRE√á√ÉO: Monitorar TODAS as migra√ß√µes (n√£o apenas server_failed).
    """
    print(f"\n[K8S_HEALTH] === MONITORAMENTO DE SA√öDE DAS MIGRA√á√ïES - STEP {current_step} ===")
    
    services_recovered = 0
    services_failed = 0
    services_converted = 0
    
    for service in Service.all():
        if not hasattr(service, '_Service__migrations') or len(service._Service__migrations) == 0:
            continue
        
        migration = service._Service__migrations[-1]
        
        # Pular migra√ß√µes j√° finalizadas
        if migration.get("end") is not None:
            continue
        
        # ‚úÖ CORRE√á√ÉO: REMOVER filtro que exclui delay_violation
        # ANTES: if migration.get("migration_reason") != "server_failed": continue
        # DEPOIS: Processar TODAS as migra√ß√µes
        
        origin = migration.get("origin")
        target = migration.get("target")

        if origin is None:
            continue 

        is_live = not migration.get("is_cold_migration", False)
        status = migration.get("status", "unknown")
        migration_reason = migration.get("migration_reason", "unknown")
        
        origin_alive = origin and origin.available
        target_alive = target and target.available
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CEN√ÅRIO 1: DESTINO FALHOU
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if not target_alive:
            # ‚úÖ CORRE√á√ÉO: Validar antes de acessar .id
            target_id = target.id if target else "None"
            origin_id = origin.id if origin else "None"
            
            print(f"[K8S_HEALTH] üî¥ Destino {target_id} FALHOU durante migra√ß√£o")
            print(f"              Service: {service.id}, Origin: {origin_id}")
            
            # Interromper migra√ß√£o atual
            migration["end"] = current_step
            migration["status"] = "interrupted"
            migration["interruption_reason"] = "target_server_failed"
            
            # Decrementar contador do destino
            if target and hasattr(target, 'ongoing_migrations'):
                target.ongoing_migrations = max(0, target.ongoing_migrations - 1)
            
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # SUBCEN√ÅRIO 1.1: DESTINO FALHA + ORIGEM VIVA (Live Migration)
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if is_live and origin_alive:
                print(f"[K8S_HEALTH] ‚úÖ Origem {origin_id} AINDA VIVA - Procurando novo destino")
                
                # Servi√ßo volta a rodar na origem (se n√£o estava)
                if service.server != origin:
                    service.server = origin
                    if service not in origin.services:
                        origin.services.append(service)
                
                service._available = True  # Garantir disponibilidade
                
                # Procurar novo destino
                app = service.application
                user = app.users[0] if app.users else None
                
                if user:
                    new_target = kubernetes_scheduler(service, user, app)
                    
                    if new_target and new_target.id != origin.id:
                        print(f"[K8S_HEALTH] üîÑ Novo destino encontrado: {new_target.id}")
                        print(f"              Reiniciando Live Migration...")
                        
                        service._available = True
                        # ‚úÖ Definir raz√£o ANTES
                        service._migration_reason = "server_failed"

                        new_target.ongoing_migrations += 1

                        service.provision(target_server=new_target)
                        
                        # Marcar nova migra√ß√£o
                        if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                            new_migration = service._Service__migrations[-1]
                            new_migration["relationships_created_by_algorithm"] = True
                            new_migration["migration_reason"] = "target_recovery"
                            new_migration["original_migration_reason"] = "server_failed"
                            new_migration["is_cold_migration"] = False
                            new_migration["origin"] = origin
                            new_migration["target"] = new_target
                            new_migration["is_retry_after_failure"] = True
                        
                        services_recovered += 1

                        _migration_counters["conversions"]["target_recovery"] += 1
                        _migration_counters["failures"]["target_failed"] += 1
                    else:
                        print(f"[K8S_HEALTH] ‚ö†Ô∏è Nenhum novo destino dispon√≠vel - Mantendo na origem")
                        services_failed += 1
            
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # SUBCEN√ÅRIO 1.2: DESTINO FALHA + ORIGEM MORTA (Cold Migration)
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            elif not origin_alive:
                print(f"[K8S_HEALTH] üî¥ Origem {origin_id} TAMB√âM MORTA")
                print(f"              Service {service.id} √ìRF√ÉO - Procurando novo destino")
                
                service._available = False  # Indispon√≠vel (√≥rf√£o)
                
                # Procurar novo destino para Cold Migration
                app = service.application
                user = app.users[0] if app.users else None
                
                if user:
                    new_target = kubernetes_scheduler(service, user, app)
                    
                    if new_target:
                        print(f"[K8S_HEALTH] üîÑ Novo destino encontrado: {new_target.id}")
                        print(f"              Iniciando Cold Migration de emerg√™ncia...")
                        
                        service._available = False
                        # ‚úÖ Definir raz√£o ANTES
                        service._migration_reason = "server_failed"

                        new_target.ongoing_migrations += 1

                        service.provision(target_server=new_target)
                        
                        # Marcar nova migra√ß√£o
                        if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                            new_migration = service._Service__migrations[-1]
                            new_migration["migration_reason"] = "orphan_recovery"
                            new_migration["original_migration_reason"] = "server_failed"
                            new_migration["is_cold_migration"] = True
                            new_migration["origin"] = None  # √ìrf√£o (sem origem v√°lida)
                            new_migration["target"] = new_target
                            new_migration["is_emergency_recovery"] = True
                        
                        services_recovered += 1

                        _migration_counters["conversions"]["orphan_recovery"] += 1
                        _migration_counters["failures"]["both_failed"] += 1
                    else:
                        print(f"[K8S_HEALTH] ‚ùå Nenhum destino dispon√≠vel - Service fica Pending")
                        services_failed += 1
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CEN√ÅRIO 2: ORIGEM FALHOU (Live Migration em andamento)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        elif is_live and not origin_alive:
            # ‚úÖ CORRE√á√ÉO: Validar antes de acessar .id
            origin_id = origin.id if origin else "None"
            target_id = target.id if target else "None"
            
            print(f"[K8S_HEALTH] üî¥ Origem {origin_id} FALHOU durante Live Migration")
            print(f"              Service: {service.id}, Target: {target_id}")
            
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # SUBCEN√ÅRIO 2.1: ORIGEM FALHA + DESTINO VIVO
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if target_alive:
                print(f"[K8S_HEALTH] ‚úÖ Destino {target_id} AINDA VIVO - Convertendo para Cold Migration")
                
                # Converter Live ‚Üí Cold Migration
                migration["is_cold_migration"] = True
                migration["converted_to_cold_at"] = current_step
                migration["conversion_reason"] = "origin_failed_during_live_migration"
                
                # For√ßar mudan√ßa para destino (j√° est√° l√° devido ao algoritmo)
                if service.server != target:
                    service.server = target
                    if service not in target.services:
                        target.services.append(service)
                
                # Marcar como indispon√≠vel (Cold Migration)
                service._available = False
                
                print(f"[K8S_HEALTH] üîÑ Live Migration convertida para Cold (origem falhou)")
                print(f"              Aguardando downloads no destino {target_id}...")
                
                services_converted += 1

                _migration_counters["conversions"]["live_to_cold"] += 1
                _migration_counters["failures"]["origin_failed"] += 1
            
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # SUBCEN√ÅRIO 2.2: AMBOS FALHARAM
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            else:
                print(f"[K8S_HEALTH] üî¥ AMBOS (origem E destino) FALHARAM!")
                print(f"              Service {service.id} PERDIDO - Procurando novo destino")
                
                # Interromper migra√ß√£o
                migration["end"] = current_step
                migration["status"] = "interrupted"
                migration["interruption_reason"] = "both_servers_failed"
                
                if target and hasattr(target, 'ongoing_migrations'):
                    target.ongoing_migrations = max(0, target.ongoing_migrations - 1)
                
                service._available = False
                
                # Procurar novo destino
                app = service.application
                user = app.users[0] if app.users else None
                
                if user:
                    new_target = kubernetes_scheduler(service, user, app)
                    
                    if new_target:
                        print(f"[K8S_HEALTH] üîÑ Novo destino encontrado: {new_target.id}")
                        print(f"              Iniciando Cold Migration de emerg√™ncia...")
                        
                        service._available = False
                        # ‚úÖ Definir raz√£o ANTES
                        service._migration_reason = "server_failed"

                        new_target.ongoing_migrations += 1

                        service.provision(target_server=new_target)
                        
                        # Marcar nova migra√ß√£o
                        if hasattr(service, '_Service__migrations') and len(service._Service__migrations) > 0:
                            new_migration = service._Service__migrations[-1]
                            new_migration["migration_reason"] = "both_failed_recovery"
                            new_migration["original_migration_reason"] = "server_failed"
                            new_migration["is_cold_migration"] = True
                            new_migration["origin"] = None
                            new_migration["target"] = new_target
                            new_migration["is_emergency_recovery"] = True
                        
                        services_recovered += 1

                        _migration_counters["failures"]["no_recovery_possible"] += 1
                    else:
                        print(f"[K8S_HEALTH] ‚ùå Nenhum destino dispon√≠vel")
                        services_failed += 1
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # RESUMO
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if services_recovered > 0 or services_failed > 0 or services_converted > 0:
        print(f"\n[K8S_HEALTH] Resumo do monitoramento:")
        print(f"              - Services recuperados: {services_recovered}")
        print(f"              - Live ‚Üí Cold convers√µes: {services_converted}")
        print(f"              - Services que falharam: {services_failed}")
    
    print(f"[K8S_HEALTH] === FIM MONITORAMENTO DE SA√öDE ===\n")


# ...existing code...

def k8s_validate_predictions(current_step):
    """
    Valida previs√µes de falha feitas anteriormente (espelho do TrustEdge).
    """
    global _k8s_prediction_quality
    
    if not _K8S_CONFIG.get('enable_failure_prediction', False):
        return
    
    # Log peri√≥dico de status
    if current_step % 100 == 0:
        pending = sum(
            1 for item in _k8s_prediction_quality["proactive_migrations"]
            if not item.get("validated", False)
        )
        if pending > 0:
            tp = _k8s_prediction_quality["true_positives"]
            fp = _k8s_prediction_quality["false_positives"]
            print(f"[K8S_VALIDATE] Step {current_step}: {pending} previs√µes pendentes "
                  f"(TP:{tp} FP:{fp})")
    
    validations_done = 0
    
    for item in _k8s_prediction_quality["proactive_migrations"]:
        # Pular j√° validadas
        if item.get("validated", False):
            continue
        
        server_id = item.get("server_id")
        deadline = item.get("deadline")
        step_predicted = item.get("step")
        
        # Validar apenas ap√≥s o prazo
        if current_step < deadline:
            continue
        
        # ‚úÖ CORRE√á√ÉO: Sintaxe correta do EdgeSimPy
        server = EdgeServer.find_by(attribute_name="id", attribute_value=server_id)
        
        if not server:
            # Servidor n√£o existe mais (caso raro)
            item["validated"] = True
            item["outcome"] = "server_not_found"
            continue
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # VERIFICAR SE SERVIDOR FALHOU NO PRAZO
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # Verificar hist√≥rico de falhas entre step_predicted e deadline
        server_failed_in_window = False
        
        if hasattr(server, 'failure_model') and hasattr(server.failure_model, 'failure_history'):
            for failure in server.failure_model.failure_history:
                failure_start = failure.get("failure_starts_at")
                
                # Falha ocorreu dentro da janela de predi√ß√£o?
                if step_predicted <= failure_start <= deadline:
                    server_failed_in_window = True
                    break
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CLASSIFICAR: TP ou FP
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        if server_failed_in_window:
            # TRUE POSITIVE: Previmos falha e ela ocorreu
            item["outcome"] = "server_failed_correctly_predicted"
            item["validated"] = True
            _k8s_prediction_quality["true_positives"] += 1
            validations_done += 1
            
            print(f"[K8S_VALIDATE] ‚úÖ TP: Server {server_id} falhou conforme previsto "
                  f"(step {step_predicted} ‚Üí falha detectada)")
        
        else:
            # FALSE POSITIVE: Previmos falha mas n√£o ocorreu
            item["outcome"] = "server_survived_validation_window"
            item["validated"] = True
            _k8s_prediction_quality["false_positives"] += 1
            validations_done += 1
            
            print(f"[K8S_VALIDATE] ‚ùå FP: Server {server_id} sobreviveu "
                  f"(step {step_predicted} ‚Üí deadline {deadline})")
    
    if validations_done > 0:
        tp = _k8s_prediction_quality["true_positives"]
        fp = _k8s_prediction_quality["false_positives"]
        print(f"[K8S_VALIDATE] {validations_done} valida√ß√µes conclu√≠das. Total: TP={tp}, FP={fp}")